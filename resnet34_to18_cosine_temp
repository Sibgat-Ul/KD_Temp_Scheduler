{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import argparse\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm\nfrom torchvision.io import read_image, ImageReadMode\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\n\nfrom torch.utils.data import DataLoader, Dataset\n\nif torch.cuda.is_available():\n    torch.set_default_device('cuda')\n\nPATH = \"/kaggle/input/imagenetmini-1000/imagenet-mini\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T12:01:32.875739Z","iopub.execute_input":"2024-10-08T12:01:32.876756Z","iopub.status.idle":"2024-10-08T12:01:39.398747Z","shell.execute_reply.started":"2024-10-08T12:01:32.876705Z","shell.execute_reply":"2024-10-08T12:01:39.397734Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ntrain_dataset = ImageFolder(\n    PATH+'/train/',\n    transform\n)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=20)\n\nvalid_dataset = ImageFolder(\n    PATH+'/val/',\n    transform\n)\n\nval_loader = DataLoader(dataset=valid_dataset, batch_size=20)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:01:39.400793Z","iopub.execute_input":"2024-10-08T12:01:39.401450Z","iopub.status.idle":"2024-10-08T12:02:08.307294Z","shell.execute_reply.started":"2024-10-08T12:01:39.401386Z","shell.execute_reply":"2024-10-08T12:02:08.306303Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import ResNet34_Weights\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nt_model = torch.hub.load('pytorch/vision:v0.10.0', model='resnet34', weights=ResNet34_Weights.DEFAULT)\ns_model = torch.hub.load('pytorch/vision:v0.10.0', model='resnet18', weights=None)\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(\n    s_model.parameters(), \n    0.001,\n    momentum=0.9,\n    weight_decay=0.0001\n)\n\nscheduler = CosineAnnealingLR(\n    optimizer,\n    100,\n)\n\ndef cosine_temperature_annealing(t_min=1, t_max=10, epoch=0, max_epoch=100):\n  temp = t_min + 0.5 * (t_max - t_min) * (1 + np.cos(epoch / max_epoch * np.pi))\n  return temp","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:02:34.834497Z","iopub.execute_input":"2024-10-08T12:02:34.834979Z","iopub.status.idle":"2024-10-08T12:02:40.401334Z","shell.execute_reply.started":"2024-10-08T12:02:34.834936Z","shell.execute_reply":"2024-10-08T12:02:40.400214Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:01<00:00, 77.4MB/s]\nUsing cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        \\\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n    \nclass ProgressMeter(object):\n    def __init__(self, num_batches, *meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def print(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\n'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']: '\n    \n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:02:53.515827Z","iopub.execute_input":"2024-10-08T12:02:53.516256Z","iopub.status.idle":"2024-10-08T12:02:53.529105Z","shell.execute_reply.started":"2024-10-08T12:02:53.516195Z","shell.execute_reply":"2024-10-08T12:02:53.528014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def kd_loss(s_logits, t_logits, temp_student, temp_teacher):\n    s_pred = F.log_softmax(torch.div(s_logits, t), dim=-1)\n    t_pred = F.softmax(torch.div(t_logits, t), dim=-1)\n    \n    loss_kd = F.kl_div(s_pred, t_pred, reduction=\"none\").sum(1).mean()\n    loss_kd *= t**2\n    \n    return loss_kd\n    \ndef train(\n    train_loader, \n    t_model, \n    s_model, \n    criterion, \n    optimizer,\n    scheduler, \n    epoch,\n    temp_teacher,\n    temp_student \n):\n    batch_time = AverageMeter('\\tTime: ', ':6.3f')\n    data_time = AverageMeter('\\tData: ', ':6.3f')\n    losses = AverageMeter('\\tLoss: ', ':.4e')\n    top1 = AverageMeter('\\tAcc@1: ', ':6.2f')\n    top5 = AverageMeter('\\tAcc@5: ', ':6.2f')\n    progress = ProgressMeter(\n        len(train_loader), \n        batch_time, \n        data_time, \n        losses, \n        top1,                \n        top5, \n        prefix=\"Epoch: {}\".format(epoch)\n    )\n    \n    # switch to train mode\n    t_model.train()\n\n    end = time.time()\n    for i, (images, target) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n        images = images.to('cuda')\n        \n        s_logits = s_model(images)\n        \n        with torch.no_grad():\n            t_logits = t_model(images)\n            \n        soft_ce_loss = kd_loss(\n            s_logits = s_logits, \n            t_logits = t_logits, \n            temp_student = temp_student, \n            temp_teacher = temp_teacher\n        )\n        \n        hard_ce_loss = criterion(s_logits, target)\n        \n        loss = .8*soft_ce_loss + .2*hard_ce_loss\n\n        # measure accuracy and record loss\n        acc1, acc5 = accuracy(s_logits, target, topk=(1, 5))\n        losses.update(loss.item(), images.size(0))\n        top1.update(acc1[0], images.size(0))\n        top5.update(acc5[0], images.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % 50 == 0:\n            progress.print(i)\n            \ndef validate(model, val_loader, epoch):\n    model = model.to('cuda')\n    \n    batch_time = AverageMeter('\\tTime: ', ':6.3f')\n    losses = AverageMeter('\\tLoss: ', ':.4e')\n    top1 = AverageMeter('\\tAcc@1: ', ':6.2f')\n    top5 = AverageMeter('\\tAcc@5: ', ':6.2f')\n    progress = ProgressMeter(\n        len(val_loader), \n        batch_time, \n        losses, \n        top1, \n        top5,                     \n        prefix='Test: '\n    )\n    running_loss = 0\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (images, target) in enumerate(val_loader):\n            images = images.to('cuda')\n            target = target.to('cuda')\n\n            # compute output\n            output = model(images)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), images.size(0))\n            top1.update(acc1[0], images.size(0))\n            top5.update(acc5[0], images.size(0))\n            \n            running_vloss = loss.item()\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % 50 == 0:\n                progress.print(i)\n        \n        avg_vloss = running_vloss / (epoch + 1)\n\n        # TODO: this should also be done with the ProgressMeter\n        print('Acc@1: {top1.avg:.3f} Acc@5: {top5.avg:.3f}'\n              .format(top1=top1, top5=top5))\n\n    return acc1, avg_vloss\n        ","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:02:54.969125Z","iopub.execute_input":"2024-10-08T12:02:54.969883Z","iopub.status.idle":"2024-10-08T12:02:54.987930Z","shell.execute_reply.started":"2024-10-08T12:02:54.969839Z","shell.execute_reply":"2024-10-08T12:02:54.986829Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"best_acc1 = 50\nbest_epoch = 0\nloss = 100\n\nfor epoch in range(0, 200):\n    t = cosine_temperature_annealing(epoch=epoch, max_epoch=200)\n    \n    train(\n        train_loader = train_loader, \n        t_model = t_model, \n        s_model = s_model, \n        criterion = criterion, \n        optimizer = optimizer, \n        scheduler = scheduler, \n        epoch = epoch, \n        temp_teacher = 4,\n        temp_student = t\n    )\n    \n    acc1, avg_loss_epoch = validate(\n        val_loader = val_loader, \n        s_model = s_model, \n        criterion = criterion, \n        epoch = epoch\n    )\n\n    # remember best acc@1 and save checkpoint\n    if avg_loss_epoch < loss and acc1 > best_acc1:\n        loss = avg_loss_epoch\n        best_acc1 = best_acc1\n        \n        print(f\"epoch: {epoch}:\\nbest acc: {acc1};best loss: {loss}\")\n        torch.save(s_model.state_dict(), '/saved/')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:02:56.703566Z","iopub.execute_input":"2024-10-08T12:02:56.703992Z","iopub.status.idle":"2024-10-08T12:02:57.577524Z","shell.execute_reply.started":"2024-10-08T12:02:56.703950Z","shell.execute_reply":"2024-10-08T12:02:57.575790Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m      6\u001b[0m     t \u001b[38;5;241m=\u001b[39m cosine_temperature_annealing(epoch\u001b[38;5;241m=\u001b[39mepoch, max_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_teacher\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_student\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     acc1, avg_loss_epoch \u001b[38;5;241m=\u001b[39m validate(\n\u001b[1;32m     21\u001b[0m         val_loader \u001b[38;5;241m=\u001b[39m val_loader, \n\u001b[1;32m     22\u001b[0m         s_model \u001b[38;5;241m=\u001b[39m s_model, \n\u001b[1;32m     23\u001b[0m         criterion \u001b[38;5;241m=\u001b[39m criterion, \n\u001b[1;32m     24\u001b[0m         epoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# remember best acc@1 and save checkpoint\u001b[39;00m\n","Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, t_model, s_model, criterion, optimizer, scheduler, epoch, temp_teacher, temp_student)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     41\u001b[0m     data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[0;32m---> 42\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     s_logits \u001b[38;5;241m=\u001b[39m s_model(images)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"],"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
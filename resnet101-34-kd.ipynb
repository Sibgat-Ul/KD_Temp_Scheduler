{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"name":"resnet101-34-kd","provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"22391982be524a558925dc71821b68ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a3fc70273c9426ea09581b6cea778df","IPY_MODEL_4c9ff69a26ce42da9f1ed276e153f828","IPY_MODEL_66e84d947d6046918ab373b1b1d757bb"],"layout":"IPY_MODEL_2826902ecf114fc28edbb58b50a8e904"}},"6a3fc70273c9426ea09581b6cea778df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f991b0fd28384b9ca54a46d43ff99ffb","placeholder":"​","style":"IPY_MODEL_d34ebfac84e648d2b7f1036b3ac4ca7c","value":"Downloading 1 files: 100%"}},"4c9ff69a26ce42da9f1ed276e153f828":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ad2ac547a5140988115f140e07c7a32","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90e6125f91154f98ac2be31f8b17e9d7","value":1}},"66e84d947d6046918ab373b1b1d757bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_670b3ccc2bdb499d9fbfef44893b6178","placeholder":"​","style":"IPY_MODEL_6ec8db58ffb24b7e9bd7264ff82e1098","value":" 1/1 [00:06&lt;00:00,  6.41s/it]"}},"2826902ecf114fc28edbb58b50a8e904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f991b0fd28384b9ca54a46d43ff99ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d34ebfac84e648d2b7f1036b3ac4ca7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ad2ac547a5140988115f140e07c7a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90e6125f91154f98ac2be31f8b17e9d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"670b3ccc2bdb499d9fbfef44893b6178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ec8db58ffb24b7e9bd7264ff82e1098":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n# # THEN FEEL FREE TO DELETE THIS CELL.\n# # NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# # ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# # NOTEBOOK.\n# import kagglehub\n# ifigotin_imagenetmini_1000_path = kagglehub.dataset_download('ifigotin/imagenetmini-1000')\n# sibgatulislam_distilled_resnet101_pytorch_default_1_path = kagglehub.model_download('sibgatulislam/distilled_resnet101/PyTorch/default/1')\n\n# print('Data source import complete.')","metadata":{"id":"CTppE0M1c3qP","outputId":"900d687c-b78f-42d1-e217-c801c8b4a5ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls -a /root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1/imagenet-mini","metadata":{"id":"jnWkUgxEedNB","outputId":"a1186d2a-4006-407a-8665-596239587aa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_model_path = \"/root/.cache/kagglehub/models/sibgatulislam/distilled_resnet101/PyTorch/default/1/best_model.pth\"\n# dataset_path = \"/root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1/imagenet-mini\"","metadata":{"id":"auMdFU77fE0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm -q\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T16:37:13.651862Z","iopub.execute_input":"2024-10-28T16:37:13.652181Z"},"id":"wvgqsUeKc3qY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get weights\nweights101 = models.ResNet101_Weights.DEFAULT\ntransforms = weights101.transforms()\n\ndataset_path = \"/kaggle/input/imagenetmini-1000/imagenet-mini\"\n\n# Transform and load your dataset\ntrain_dataset = datasets.ImageFolder(\n    dataset_path + '/train',\n    transform=transforms\n)\n\n# DataLoader for the validation set (adjust the path accordingly)\nval_dataset = datasets.ImageFolder(\n    dataset_path + '/val',\n    transform=transforms\n)\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"RibJfGLZfeFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define temperature and alpha for distillation\nTEMPERATURE = 3.0\nALPHA = 0.95\n\ntrain_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n\n# Load Teacher and Student Models\nteacher_model = models.resnet101(\n    weights=weights101\n).to(device)\n\n# print(\"======TEACHER======\")\n# print(teacher_model)\n\nstudent_model = models.resnet34(weights=None).to(device)\n\n# print(\"======STUDENT======\")\n# print(student_model)\n\n# Freeze teacher model parameters\nfor param in teacher_model.parameters():\n    param.requires_grad = False\n\n# Define loss functions\ncriterion = nn.CrossEntropyLoss()\ndistillation_loss = nn.KLDivLoss(reduction='batchmean')\n\n# Define optimizer for the student model\n# optimizer = optim.Adam(student_model.parameters(), lr=0.001)\noptimizer = optim.SGD(student_model.parameters(), lr=0.1, momentum=0.9, nesterov=True)\n","metadata":{"id":"AF9xaZ5igsiy","outputId":"5958dd0a-0181-4dcd-eb5c-067cd1bc63cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the top-k accuracy for the specified values of k.\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n# Knowledge Distillation Function\ndef distillation_loss_fn(student_logits, teacher_logits, labels):\n    # Regular cross-entropy loss\n    loss = criterion(student_logits, labels)\n\n    # Softened outputs for distillation\n    distillation_loss_value = distillation_loss(\n        torch.nn.functional.log_softmax(student_logits / TEMPERATURE, dim=1),\n        torch.nn.functional.softmax(teacher_logits / TEMPERATURE, dim=1)\n    ) * (TEMPERATURE ** 2)\n\n    # Weighted sum of both losses\n    return ALPHA * distillation_loss_value + (1 - ALPHA) * loss\n\n# Function to evaluate model accuracy\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    correct_top1 = 0\n    correct_top5 = 0\n    total = 0\n    print(\"total batches: \", len(dataloader))\n\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n\n            # Top-1 accuracy\n            _, predicted = outputs.max(1)\n            correct_top1 += (predicted == labels).sum().item()\n\n            # Top-5 accuracy\n            _, top5_pred = outputs.topk(5, dim=1)\n            correct_top5 += (top5_pred == labels.view(-1, 1)).sum().item()\n\n            total += labels.size(0)\n\n    top1_accuracy = 100 * correct_top1 / total\n    top5_accuracy = 100 * correct_top5 / total\n    return top1_accuracy, top5_accuracy\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=128,\n    shuffle=False\n)\n\n# Training Loop\ndef train_student(teacher_model, student_model, train_dataloader, val_loader optimizer, epochs=10):\n    student_model.train()\n    teacher_model.eval()\n\n    best_loss = float('inf')\n    best_acc = 50.0\n    \n    best_acc1 = 50.0\n    best_acc5 = 50.0\n    \n    val_acc1 = 0.0\n    val_acc5 = 0.0\n\n\n    history = {\n        'loss': [],\n        'acc1': [],\n        'acc5': []\n    }\n\n    for epoch in range(epochs):\n        epoch_loss = 0.0\n        epoch_acc1 = 0.0\n        epoch_acc5 = 0.0\n#         pbar = tqdm.tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}')\n\n        for i, (images, labels) in enumerate(train_dataloader):\n            inputs, labels = images.to(device), labels.to(device)\n\n            # Get teacher predictions (detach to avoid computing gradients on teacher)\n            with torch.no_grad():\n                teacher_logits = teacher_model(inputs)\n\n            # Get student predictions\n            student_logits = student_model(inputs)\n\n            # Compute loss\n            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            acc1, acc5 = accuracy(student_logits, labels, (1, 5))\n\n            # Update running metrics\n            batch_size = images.size(0)\n            epoch_loss += loss.item() * batch_size\n            epoch_acc1 += acc1.item() * batch_size\n            epoch_acc5 += acc5.item() * batch_size\n\n#             # Update progress bar\n#             pbar.set_postfix({\n#                 'loss': f'{loss.item():.4f}',\n#                 'acc1': f'{acc1.item():.2f}%',\n#                 'acc5': f'{acc5.item():.2f}%'\n#             })\n\n            if i%100 == 0:\n                print(\n                    f\"epoch: {epoch+1} || batch/batch_size: {i+1}/{batch_size} || loss: {loss.item():.4f} || acc1: {acc1.item():.2f} || acc5: {acc5.item():.2f}\"\n                )\n\n        # Calculate epoch metrics\n        num_samples = len(train_loader.dataset)\n        epoch_loss /= num_samples\n        epoch_acc1 /= num_samples\n        epoch_acc5 /= num_samples\n\n        # Update history\n        history['loss'].append(epoch_loss)\n        history['acc1'].append(epoch_acc1)\n        history['acc5'].append(epoch_acc5)\n\n        # Print epoch summary\n        print(f'\\nEpoch {epoch+1}/{epochs}:')\n        print(f'Loss: {epoch_loss:.4f}')\n        print(f'Accuracy@1: {epoch_acc1:.2f}%')\n        print(f'Accuracy@5: {epoch_acc5:.2f}%')\n        \n        if (epoch+1)%10 == 0:\n            top1_acc, top5_acc = evaluate_model(\n                student_model, \n                val_loader, \n                device\n            )\n            \n            val_acc1 = top1_acc\n            val_acc5 = top5_acc\n            \n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': student_model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'acc@1': top1_acc,\n                'acc@5': top5_acc,\n            }, f'./best_model-{epoch+1}.pth')\n\n            \n            print(f\"Student Model with Distillation - Top-1 Accuracy: {top1_acc:.2f}%, Top-5 Accuracy: {top5_acc:.2f}%\")\n            \n        # Save best model\n        if epoch_loss < best_loss and best_acc1 < val_acc1 and best_acc5 < val_acc5:\n            best_acc1 = val_acc1\n            best_acc5 = val_acc5\n            best_loss = epoch_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': student_model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': best_loss,\n                'best_acc@1': best_acc1,\n                'best_acc@5': best_acc5,\n                'accuracy': epoch_acc1\n            }, './best_model.pth')\n            \n    return student_model","metadata":{"id":"f36YVi3ic3qZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the student model\ntrained_student_model = train_student(teacher_model, student_model, train_loader, val_loader optimizer, epochs=50)","metadata":{"id":"Cbwr-l0Nc3qb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trained_student_model = models.resnet34(weights=None)\n# trained_student_model.load_state_dict(torch.load(best_model_path, weights_only=True)[\"model_state_dict\"])\n# trained_student_model.to(device)","metadata":{"id":"cGgj523Yc3qc","outputId":"5eb0b496-7896-461b-d5ec-a8883c7079f6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1u3PM3ulc3qd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top1_teacher, top5_teacher = evaluate_model(teacher_model, val_loader, device)\nprint(f\"Teacher Model - Top-1 Accuracy: {top1_teacher:.2f}%, Top-5 Accuracy: {top5_teacher:.2f}%\")\n\n# Train student_model here without distillation, then evaluate\nstudent_model_wokd = models.resnet34(weights=models.ResNet34_Weights.DEFAULT).to(device)\ntop1_student_baseline, top5_student_baseline = evaluate_model(student_model_wokd, val_loader, device)\nprint(f\"Student Model Baseline - Top-1 Accuracy: {top1_student_baseline:.2f}%, Top-5 Accuracy: {top5_student_baseline:.2f}%\")\n\n# Train the student model with knowledge distillation and evaluate\n# (Use the previously provided code for distillation training)\ntop1_student_distilled, top5_student_distilled = evaluate_model(trained_student_model, val_loader, device)\nprint(f\"Student Model with Distillation - Top-1 Accuracy: {top1_student_distilled:.2f}%, Top-5 Accuracy: {top5_student_distilled:.2f}%\")","metadata":{"id":"f7marGmDkJ6U","outputId":"541737a6-b0a0-43f4-fde2-5d0613124a40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tr_evaluate_model(model, dataloader, device):\n    model.eval()\n    correct_top1 = 0\n    correct_top5 = 0\n    total = 0\n    print(\"total batches: \", len(dataloader))\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloader):\n            if (i+1) %32 == 0:\n                print(f\"batch: {i+1}\")\n                print(\"label size: \", labels.size(0))\n                break\n\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n\n            # Top-1 accuracy\n            _, predicted = outputs.max(1)\n            correct_top1 += (predicted == labels).sum().item()\n\n            # Top-5 accuracy\n            _, top5_pred = outputs.topk(5, dim=1)\n            correct_top5 += (top5_pred == labels.view(-1, 1)).sum().item()\n\n            total += labels.size(0)\n\n    top1_accuracy = 100 * correct_top1 / total\n    top5_accuracy = 100 * correct_top5 / total\n    return top1_accuracy, top5_accuracy\n","metadata":{"id":"MD8-gaMDluZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top1_student_distilled, top5_student_distilled = tr_evaluate_model(trained_student_model, DataLoader(train_dataset, batch_size=512, shuffle=True), device)\n# print(f\"Student Model with Distillation - Top-1 Accuracy: {top1_student_distilled:.2f}%, Top-5 Accuracy: {top5_student_distilled:.2f}%\")","metadata":{"id":"gqGisMjbgjzM","outputId":"3178fe58-8cda-4516-e764-30789037b724"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"6ZT6K6eujYp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-zzYdB7zl-xz"},"execution_count":null,"outputs":[]}]}